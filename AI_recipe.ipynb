{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf264516-5eb9-4de7-999f-0698bae6aa1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Part 1: Data Exploration and Analysis\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "recipes = pd.read_csv('RAW_recipes.csv')\n",
    "interactions = pd.read_csv('RAW_interactions.csv')\n",
    "df = pd.read_pickle('ingr_map.pkl')\n",
    "\n",
    "print(\"Recipes Dataset Sample:\\n\", recipes.head())\n",
    "print(\"\\n\\nInteractions Dataset Sample:\\n\", recipes.head())\n",
    "print(\"\\n\\nIngr Map Sample:\\n\", recipes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634f9cdd-f328-4ed6-8078-530a23b04b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Further Data Inspection\n",
    "\n",
    "print(\"\\nRecipes Dataseet info:\\n\",recipes.info())\n",
    "print(\"\\n\\nInteractions Dataset info:\\n\",interactions.info())\n",
    "print(\"\\n\\nMapping Key  info:\\n\",df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6b84da-fed7-460d-a29b-0f72276f2727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling Missing values\n",
    "print(\"\\nMissing Data in Recipes:\\n\")\n",
    "print(recipes.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing Data in Interactions:\\n\")\n",
    "print(interactions.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac564066-88c8-421b-a359-93ac0ca5a236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling missing rows with placeholder strings\n",
    "recipes['description'] = recipes['description'].fillna('No description available')\n",
    "interactions['review'] = interactions['review'].fillna('No reviews available')\n",
    "\n",
    "print(\"\\nMissing Data in Recipes:\\n\")\n",
    "print(recipes.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing Data in Interactions:\\n\")\n",
    "print(interactions.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848cf569-3fdf-46a9-a274-0b75b8b2131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping Rows with missing values in critical columns\n",
    "recipes = recipes.dropna(subset=['name', 'ingredients', 'steps'])\n",
    "interactions = interactions.dropna(subset=['rating'])\n",
    "\n",
    "print(\"\\nCleaned Recipes Dataset Info:\")\n",
    "print(recipes.info())\n",
    "\n",
    "\n",
    "print(\"\\nCleaned Interactions Dataset Info:\")\n",
    "print(interactions .info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022b0cff-3d64-4d01-9117-d5bb15faa64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize Ingredients\n",
    "\n",
    "def normalize_ingredients(ingredients_list, ingr_map):\n",
    "    normalized = [ingr_map.get(ingredient, ingredient) for ingredient in ingredients_list]\n",
    "    return normalized\n",
    "\n",
    "\n",
    "recipes['ingredients'] = recipes['ingredients'].apply(lambda x: x if isinstance(x, list) else eval(x))\n",
    "recipes['normalized_ingredients'] = recipes['ingredients'].apply(lambda x: normalize_ingredients(x, df))\n",
    "print(\"Done normalizing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79782a53-21a9-491c-a335-7f3856633f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#Feature Engineering\n",
    "\n",
    "recipes['num_ingredients'] = recipes['ingredients'].apply(len)\n",
    "recipes['num_steps'] = recipes['steps'].apply(lambda x: len(eval(x)))\n",
    "\n",
    "#Parsing Nutritional Information \n",
    "nutrition_columns = ['calories', 'total_fat', 'sugar', 'sodium', 'protein', 'saturated_fat', 'carbohydrates']\n",
    "recipes[nutrition_columns] = recipes['nutrition'].apply(\n",
    "    lambda x: pd.Series(eval(x)) if isinstance(x, str) else pd.Series([np.nan]*7)\n",
    ")\n",
    "\n",
    "#Visualization\n",
    "#Distribution of # of ingredients\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(recipes['num_ingredients'], kde=False, bins=20, color='blue')\n",
    "plt.title(\"Distribution of Number of Ingredients per Recipe\")\n",
    "plt.xlabel(\"Number of Ingredients\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "#Distribution of Ratings\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(interactions['rating'], kde=False, bins=10, color='green')\n",
    "plt.title(\"Distribution of Ratings\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "recipes.to_csv('cleaned_recipes.csv', index=False)\n",
    "interactions.to_csv('cleaned_interactions.csv', index=False)\n",
    "\n",
    "print(\"\\nData Cleaning and Feature Engineering Complete!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd6d0fa-2723-47b8-9c27-0503433618be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Part 2: Building the Recommendation System\n",
    "\n",
    "recipes = pd.read_csv('cleaned_recipes.csv')\n",
    "interactions = pd.read_csv('cleaned_interactions.csv')\n",
    "\n",
    "print(recipes.head())\n",
    "print(interactions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5cfc46-523f-4126-a8ce-5d3edea4c3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging and Preparing Data\n",
    "\n",
    "merged_data = pd.merge(interactions, recipes, left_on='recipe_id', right_on='id', how='inner')\n",
    "\n",
    "#Confirm Structure\n",
    "print(merged_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283f4cd1-c943-4830-b349-67cd98e03799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Optional) Finding 'common' ingredients\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "recipes['ingredients'] = recipes['ingredients'].apply(lambda x: x if isinstance(x, list) else eval(x))\n",
    "\n",
    "all_ingredients = [ingredient for recipe in recipes['ingredients'] for ingredient in recipe]\n",
    "\n",
    "# Count the frequency of each ingredient\n",
    "ingredient_counts = Counter(all_ingredients)\n",
    "\n",
    "# top 100 most common ingredients\n",
    "N = 20\n",
    "common_ingredients = [ingredient for ingredient, count in ingredient_counts.most_common(N)]\n",
    "\n",
    "print(f\"Top {N} common ingredients: {common_ingredients}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708d003f-d86c-4469-9d9b-33020389abb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collaborative Filtering\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "interactions['rating'] = interactions['rating'].astype(float)\n",
    "\n",
    "# Create a sparse interaction matrix\n",
    "interaction_matrix_sparse = csr_matrix(\n",
    "    (interactions['rating'], (interactions['user_id'], interactions['recipe_id']))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e373f4-be6b-427f-95dd-713a5b19a6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to include only users who have rated more than a threshold\n",
    "user_threshold = 10\n",
    "active_users = interactions['user_id'].value_counts()\n",
    "active_users = active_users[active_users > user_threshold].index\n",
    "interactions_filtered = interactions[interactions['user_id'].isin(active_users)]\n",
    "\n",
    "# Filter to include only recipes with many ratings\n",
    "recipe_threshold = 10\n",
    "popular_recipes = interactions['recipe_id'].value_counts()\n",
    "popular_recipes = popular_recipes[popular_recipes > recipe_threshold].index\n",
    "interactions_filtered = interactions_filtered[interactions_filtered['recipe_id'].isin(popular_recipes)]\n",
    "\n",
    "\n",
    "interaction_matrix_sparse = csr_matrix(\n",
    "    (interactions_filtered['rating'], (interactions_filtered['user_id'], interactions_filtered['recipe_id']))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f3143e-59ff-45c3-a47f-8c99068c0f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsampling interaction matrix to avoid memory crashes\n",
    "interaction_matrix_sparse = interaction_matrix_sparse[:5000, :500]\n",
    "#Batch Processing for SVD\n",
    "\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "#perform SVD\n",
    "\n",
    "U, sigma, Vt = svds(interaction_matrix_sparse[:5000, :500], k=20)\n",
    "sigma = np.diag(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a06ada-8d1c-4952-bc7e-2a37099daaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reccomendation Phase\n",
    "\n",
    "#Reconstructing the approximated interaction matrix\n",
    "reconstructed_matrix = np.dot(np.dot(U, sigma), Vt)\n",
    "\n",
    "#Ensure values are between the expected range\n",
    "reconstructed_matrix = np.clip(reconstructed_matrix, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821cc8f3-df02-42af-98ec-9854c8d35c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_users = interactions['user_id'].drop_duplicates().iloc[:reconstructed_matrix.shape[0]]\n",
    "sample_users = sample_users.iloc[:reconstructed_matrix.shape[0]]\n",
    "sample_recipes = interactions['recipe_id'].drop_duplicates().iloc[:reconstructed_matrix.shape[1]]\n",
    "\n",
    "sample_recipes = sample_recipes.iloc[:reconstructed_matrix.shape[1]]\n",
    "recipe_id_mapping = {recipe: idx for idx, recipe in enumerate(sample_recipes)}\n",
    "index_to_recipe_id = {idx: recipe for recipe, idx in recipe_id_mapping.items()}\n",
    "user_to_index = {user_id: index for index, user_id in enumerate(interactions['user_id'].unique())}\n",
    "\n",
    "# # Check if the problematic User ID is included\n",
    "# if user_id_to_check not in sample_users.values:\n",
    "#     print(f\"Adding User ID {user_id_to_check} to the dataset.\")\n",
    "#     #sample_users = sample_users.append(pd.Series([user_id_to_check])).drop_duplicates()\n",
    "#     sample_users = pd.concat([sample_users, pd.Series([user_id_to_check])]).drop_duplicates()\n",
    "    \n",
    "user_id_mapping = {user_id: idx for idx, user_id in enumerate(sample_users)}\n",
    "#print(f\"User ID {user_id_to_check} added to user_id_mapping.\")\n",
    "\n",
    "new_user_row = np.zeros(reconstructed_matrix.shape[1])  # A row of zeros for all recipes\n",
    "reconstructed_matrix = np.vstack([reconstructed_matrix, new_user_row])\n",
    "print(f\"Reconstructed matrix extended. New shape: {reconstructed_matrix.shape}\")\n",
    "\n",
    "if 'reconstructed_matrix' not in globals():\n",
    "    print(\"Error: 'reconstructed_matrix' is not defined. Please ensure it is calculated.\")\n",
    "else:\n",
    "    # Function to recommend recipes for a given user\n",
    "    def recommended_recipes(user_id, reconstructed_matrix, recipe_mapping, top_n=5):\n",
    "    # Check if user exists in the mapping\n",
    "        if user_id not in user_id_mapping:\n",
    "            print(f\"User ID {user_id} not found. Returning default recommendations.\")\n",
    "            return [recipe_mapping[idx] for idx in range(top_n)]\n",
    "    \n",
    "        user_index = user_id_mapping[user_id]\n",
    "        if user_index >= reconstructed_matrix.shape[0]:\n",
    "            print(f\"User index {user_index} is out of bounds for reconstructed_matrix.\")\n",
    "            return []\n",
    "    \n",
    "        # Get predicted ratings for the user\n",
    "        predicted_ratings = reconstructed_matrix[user_index]\n",
    "    \n",
    "        # Check bounds for recipe indices\n",
    "        if len(predicted_ratings) != len(recipe_mapping):\n",
    "            print(f\"Mismatch: {len(predicted_ratings)} predictions vs {len(recipe_mapping)} recipes.\")\n",
    "            return []\n",
    "    \n",
    "        # Get top N recipes\n",
    "        recommended_indices = np.argsort(predicted_ratings)[::-1][:top_n]\n",
    "        recommended_recipes = [recipe_mapping[idx] for idx in recommended_indices if idx in recipe_mapping]\n",
    "        return recommended_recipes\n",
    "\n",
    "    # Sample user and get recommendations\n",
    "    sample_users = interactions['user_id'].drop_duplicates().sample(n=10000)\n",
    "    user_id = sample_users.iloc[0]  # Choose the first sample user\n",
    "\n",
    "    top_recipes = recommended_recipes(user_id, reconstructed_matrix, index_to_recipe_id)\n",
    "\n",
    "    if top_recipes:\n",
    "        print(f\"Top recommended recipes for user {user_id}: {top_recipes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9b4933-f0c6-490a-931c-6fbca499ba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the focus user to sample_users and extend reconstructed_matrix\n",
    "user_id_to_check = 1858424\n",
    "focus_user_id = user_id_to_check\n",
    "\n",
    "if user_id_to_check not in sample_users.values:\n",
    "    print(f\"Adding User ID {user_id_to_check} to sample_users and extending reconstructed_matrix.\")\n",
    "    sample_users = pd.concat([sample_users, pd.Series([user_id_to_check])]).reset_index(drop=True)\n",
    "    \n",
    "    # Extend reconstructed_matrix\n",
    "    new_user_row = np.zeros(reconstructed_matrix.shape[1])  # Add a row for the new user\n",
    "    reconstructed_matrix = np.vstack([reconstructed_matrix, new_user_row])\n",
    "    print(f\"Reconstructed matrix extended. New shape: {reconstructed_matrix.shape}\")\n",
    "\n",
    "# Trim sample_users to match reconstructed_matrix dimensions\n",
    "sample_users = sample_users.iloc[:reconstructed_matrix.shape[0]].reset_index(drop=True)\n",
    "\n",
    "# Rebuild user_id_mapping\n",
    "user_id_mapping = {user_id: idx for idx, user_id in enumerate(sample_users)}\n",
    "\n",
    "# Validate focus user\n",
    "focus_user_index = user_id_mapping.get(focus_user_id, -1)\n",
    "\n",
    "if focus_user_index < 0 or focus_user_index >= reconstructed_matrix.shape[0]:\n",
    "    print(f\"Error: User index {focus_user_index} is out of bounds for reconstructed_matrix.\")\n",
    "else:\n",
    "    print(f\"Focus user {focus_user_id} is valid and mapped to index {focus_user_index}.\")\n",
    "\n",
    "# Generate recommendations for the focus user\n",
    "top_recipes = recommended_recipes(focus_user_id, reconstructed_matrix, index_to_recipe_id, top_n=5)\n",
    "\n",
    "if top_recipes:\n",
    "    print(f\"Top recommended recipes for user {focus_user_id}: {top_recipes}\")\n",
    "else:\n",
    "    print(f\"No recommendations available for user {focus_user_id}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43325c55-56e7-4686-b2c2-64e4e4e55d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the recommended recipes from the dataset\n",
    "recommended_recipes_df = recipes[recipes['id'].isin([521583, 223868, 205535, 211570, 206084])]\n",
    "print(recommended_recipes_df[['id','name', 'description']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319dfc22-5b21-448f-9c83-b707e29bbb9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
